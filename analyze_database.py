#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è§£æãƒ„ãƒ¼ãƒ«
GROUPSå¤‰æ•°ã®è¢«å†™ä½“ã®æ•°ã¨çµ„ã¿åˆã‚ã›ã”ã¨ã«ç”»åƒæ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆã™ã‚‹
"""

import sqlite3
from collections import defaultdict, Counter
from math import inf
import json
from database import ImageDatabase

# app.pyã®GROUPSå¤‰æ•°ã‚’å†å®šç¾©
GROUPS = {
    "girls": {
        "1girl": (1, 1),
        "2girls": (2, 2),
        "3girls": (3, 3),
        "4girls": (4, 4),
        "5girls": (5, 5),
        "6girls": (6, 6),
        "multiple_girls": (2, inf),
    },
    "boys": {
        "1boy": (1, 1),
        "2boys": (2, 2),
        "3boys": (3, 3),
        "4boys": (4, 4),
        "5boys": (5, 5),
        "6boys": (6, 6),
        "multiple_boys": (2, inf),
    },
    "solo": {
        "solo": (1, 1),           # ç·ã‚­ãƒ£ãƒ©æ•° = 1 ã®ã‚·ã‚°ãƒŠãƒ«
    },
}

class DatabaseAnalyzer:
    def __init__(self, db_path="image_search.db"):
        self.db_path = db_path
        self.db = ImageDatabase(db_path)
    
    def get_all_group_tags(self):
        """GROUPSå¤‰æ•°ã«å«ã¾ã‚Œã‚‹å…¨ã¦ã®ã‚¿ã‚°ã‚’å–å¾—"""
        all_tags = set()
        for group_name, tag_dict in GROUPS.items():
            all_tags.update(tag_dict.keys())
        return all_tags
    
    def analyze_tag_combinations(self):
        """è¢«å†™ä½“ã®æ•°ã¨çµ„ã¿åˆã‚ã›ã”ã¨ã«ç”»åƒæ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ"""
        print("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è§£æã‚’é–‹å§‹ã—ã¾ã™...")
        
        conn = self.db.get_connection()
        cursor = conn.cursor()
        
        # å…¨ç”»åƒæ•°ã‚’å–å¾—
        cursor.execute('SELECT COUNT(*) FROM images')
        total_images = cursor.fetchone()[0]
        print(f"ç·ç”»åƒæ•°: {total_images:,}ä»¶")
        
        # GROUPSå¤‰æ•°ã«å«ã¾ã‚Œã‚‹ã‚¿ã‚°ã®ä½¿ç”¨çŠ¶æ³ã‚’å–å¾—
        group_tags = self.get_all_group_tags()
        tag_placeholders = ','.join(['?' for _ in group_tags])
        
        cursor.execute(f'''
            SELECT t.tag_name, COUNT(it.image_id) as usage_count
            FROM tags t
            LEFT JOIN image_tags it ON t.id = it.tag_id
            WHERE t.tag_name IN ({tag_placeholders})
            GROUP BY t.tag_name
            ORDER BY usage_count DESC
        ''', list(group_tags))
        
        tag_usage = dict(cursor.fetchall())
        print(f"\nGROUPSå¤‰æ•°ã«å«ã¾ã‚Œã‚‹ã‚¿ã‚°ã®ä½¿ç”¨çŠ¶æ³:")
        for tag, count in tag_usage.items():
            print(f"  {tag}: {count:,}ä»¶")
        
        # å„ç”»åƒãŒã©ã®GROUPSã‚¿ã‚°ã‚’æŒã£ã¦ã„ã‚‹ã‹ã‚’å–å¾—
        cursor.execute(f'''
            SELECT i.id, GROUP_CONCAT(t.tag_name) as tags
            FROM images i
            LEFT JOIN image_tags it ON i.id = it.image_id
            LEFT JOIN tags t ON it.tag_id = t.id AND t.tag_name IN ({tag_placeholders})
            GROUP BY i.id
        ''', list(group_tags))
        
        image_tags = cursor.fetchall()
        conn.close()
        
        # çµ„ã¿åˆã‚ã›åˆ¥ã®çµ±è¨ˆã‚’ä½œæˆ
        combination_stats = defaultdict(int)
        tag_combination_counter = Counter()
        
        # å„ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥ã®çµ±è¨ˆ
        group_stats = {group_name: defaultdict(int) for group_name in GROUPS.keys()}
        
        print(f"\nç”»åƒã®ã‚¿ã‚°çµ„ã¿åˆã‚ã›ã‚’è§£æä¸­... ({len(image_tags):,}ä»¶)")
        
        for image_id, tags_str in image_tags:
            if tags_str:
                image_tags_set = set(tags_str.split(','))
            else:
                image_tags_set = set()
            
            # å„ã‚°ãƒ«ãƒ¼ãƒ—ã§ã®ã‚¿ã‚°å­˜åœ¨ã‚’ãƒã‚§ãƒƒã‚¯
            group_presence = {}
            for group_name, tag_dict in GROUPS.items():
                present_tags = image_tags_set.intersection(set(tag_dict.keys()))
                group_presence[group_name] = present_tags
            
            # çµ„ã¿åˆã‚ã›ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¨˜éŒ²
            combination_key = []
            for group_name in sorted(GROUPS.keys()):
                if group_presence[group_name]:
                    tags_in_group = sorted(list(group_presence[group_name]))
                    combination_key.append(f"{group_name}:{'+'.join(tags_in_group)}")
                else:
                    combination_key.append(f"{group_name}:none")
            
            combination_str = " | ".join(combination_key)
            combination_stats[combination_str] += 1
            
            # å€‹åˆ¥ã‚¿ã‚°ã®çµ„ã¿åˆã‚ã›ã‚‚ã‚«ã‚¦ãƒ³ãƒˆ
            if image_tags_set:
                sorted_tags = tuple(sorted(image_tags_set))
                tag_combination_counter[sorted_tags] += 1
            
            # å„ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥ã®çµ±è¨ˆ
            for group_name, present_tags in group_presence.items():
                if present_tags:
                    for tag in present_tags:
                        group_stats[group_name][tag] += 1
                else:
                    group_stats[group_name]["none"] += 1
        
        return {
            'total_images': total_images,
            'tag_usage': tag_usage,
            'combination_stats': dict(combination_stats),
            'tag_combination_counter': dict(tag_combination_counter),
            'group_stats': {k: dict(v) for k, v in group_stats.items()}
        }
    
    def print_analysis_results(self, results):
        """è§£æçµæœã‚’è¦‹ã‚„ã™ãè¡¨ç¤º"""
        print("\n" + "="*80)
        print("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è§£æçµæœ")
        print("="*80)
        
        print(f"\nğŸ“Š åŸºæœ¬çµ±è¨ˆ:")
        print(f"  ç·ç”»åƒæ•°: {results['total_images']:,}ä»¶")
        
        print(f"\nğŸ·ï¸  GROUPSã‚¿ã‚°ä½¿ç”¨çŠ¶æ³:")
        for tag, count in sorted(results['tag_usage'].items(), key=lambda x: x[1], reverse=True):
            percentage = (count / results['total_images']) * 100
            print(f"  {tag:15}: {count:8,}ä»¶ ({percentage:5.1f}%)")
        
        print(f"\nğŸ‘¥ ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥çµ±è¨ˆ:")
        for group_name, stats in results['group_stats'].items():
            print(f"\n  ã€{group_name.upper()}ã€‘")
            total_in_group = sum(count for tag, count in stats.items() if tag != "none")
            none_count = stats.get("none", 0)
            
            for tag, count in sorted(stats.items(), key=lambda x: x[1], reverse=True):
                if tag == "none":
                    percentage = (count / results['total_images']) * 100
                    print(f"    {tag:15}: {count:8,}ä»¶ ({percentage:5.1f}%) - ã‚¿ã‚°ãªã—")
                else:
                    percentage = (count / results['total_images']) * 100
                    print(f"    {tag:15}: {count:8,}ä»¶ ({percentage:5.1f}%)")
        
        print(f"\nğŸ”„ çµ„ã¿åˆã‚ã›ãƒ‘ã‚¿ãƒ¼ãƒ³çµ±è¨ˆ (ä¸Šä½20ä½):")
        sorted_combinations = sorted(results['combination_stats'].items(), 
                                   key=lambda x: x[1], reverse=True)
        
        for i, (combination, count) in enumerate(sorted_combinations[:20], 1):
            percentage = (count / results['total_images']) * 100
            print(f"  {i:2d}. {count:8,}ä»¶ ({percentage:5.1f}%) - {combination}")
        
        print(f"\nğŸ“ˆ ã‚ˆãä½¿ã‚ã‚Œã‚‹ã‚¿ã‚°çµ„ã¿åˆã‚ã› (ä¸Šä½10ä½):")
        sorted_tag_combinations = sorted(results['tag_combination_counter'].items(),
                                       key=lambda x: x[1], reverse=True)
        
        for i, (tags, count) in enumerate(sorted_tag_combinations[:10], 1):
            percentage = (count / results['total_images']) * 100
            tags_str = " + ".join(tags)
            print(f"  {i:2d}. {count:8,}ä»¶ ({percentage:5.1f}%) - {tags_str}")
    
    def suggest_database_partitioning(self, results):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆ†å‰²ã®ææ¡ˆ"""
        print(f"\n" + "="*80)
        print("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆ†å‰²ææ¡ˆ")
        print("="*80)
        
        total_images = results['total_images']
        
        # ä¸»è¦ãªåˆ†å‰²è»¸ã‚’ç‰¹å®š
        print(f"\nğŸ’¡ åˆ†å‰²ææ¡ˆ:")
        
        # 1. äººæ•°ã«ã‚ˆã‚‹åˆ†å‰²
        print(f"\n1ï¸âƒ£  äººæ•°ã«ã‚ˆã‚‹åˆ†å‰²:")
        girls_stats = results['group_stats']['girls']
        boys_stats = results['group_stats']['boys']
        solo_stats = results['group_stats']['solo']
        
        # ã‚½ãƒ­ç”»åƒï¼ˆ1äººã®ã¿ï¼‰
        solo_only = solo_stats.get('solo', 0)
        
        # 2äººã®ç”»åƒ
        two_girls = girls_stats.get('2girls', 0)
        two_boys = boys_stats.get('2boys', 0)
        
        # è¤‡æ•°äººã®ç”»åƒï¼ˆ3äººä»¥ä¸Šï¼‰
        multiple_girls = girls_stats.get('multiple_girls', 0)
        multiple_boys = boys_stats.get('multiple_boys', 0)
        three_plus_girls = girls_stats.get('3girls', 0) + girls_stats.get('4girls', 0) + girls_stats.get('5girls', 0)
        three_plus_boys = boys_stats.get('3boys', 0) + boys_stats.get('4boys', 0) + boys_stats.get('5boys', 0)
        
        print(f"  - 1äººï¼ˆã‚½ãƒ­ï¼‰: {solo_only:,}ä»¶ ({solo_only/total_images*100:.1f}%)")
        print(f"  - 2äºº: {two_girls + two_boys:,}ä»¶ ({(two_girls + two_boys)/total_images*100:.1f}%)")
        print(f"  - 3äººä»¥ä¸Š: {three_plus_girls + three_plus_boys:,}ä»¶ ({(three_plus_girls + three_plus_boys)/total_images*100:.1f}%)")
        print(f"  - è¤‡æ•°äººï¼ˆmultiple_*ï¼‰: {multiple_girls + multiple_boys:,}ä»¶ ({(multiple_girls + multiple_boys)/total_images*100:.1f}%)")
        
        # 2. æ€§åˆ¥ã«ã‚ˆã‚‹åˆ†å‰²
        print(f"\n2ï¸âƒ£  æ€§åˆ¥ã«ã‚ˆã‚‹åˆ†å‰²:")
        girls_only = girls_stats.get('none', 0)  # å¥³æ€§ã‚¿ã‚°ãªã—
        boys_only = boys_stats.get('none', 0)    # ç”·æ€§ã‚¿ã‚°ãªã—
        
        # å¥³æ€§ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚’å«ã‚€ç”»åƒ
        girls_images = total_images - girls_only
        # ç”·æ€§ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚’å«ã‚€ç”»åƒ
        boys_images = total_images - boys_only
        # ä¸¡æ–¹ã‚’å«ã‚€ç”»åƒ
        both_images = girls_images + boys_images - total_images
        # å¥³æ€§ã®ã¿
        girls_only_images = girls_images - both_images
        # ç”·æ€§ã®ã¿
        boys_only_images = boys_images - both_images
        # ã©ã¡ã‚‰ã‚‚å«ã¾ãªã„
        neither_images = total_images - girls_images - boys_images + both_images
        
        print(f"  - å¥³æ€§ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®ã¿: {girls_only_images:,}ä»¶ ({girls_only_images/total_images*100:.1f}%)")
        print(f"  - ç”·æ€§ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®ã¿: {boys_only_images:,}ä»¶ ({boys_only_images/total_images*100:.1f}%)")
        print(f"  - ä¸¡æ–¹å«ã‚€: {both_images:,}ä»¶ ({both_images/total_images*100:.1f}%)")
        print(f"  - ã©ã¡ã‚‰ã‚‚å«ã¾ãªã„: {neither_images:,}ä»¶ ({neither_images/total_images*100:.1f}%)")
        
        # 3. æ¨å¥¨åˆ†å‰²æˆ¦ç•¥
        print(f"\n3ï¸âƒ£  æ¨å¥¨åˆ†å‰²æˆ¦ç•¥:")
        
        # ã‚½ãƒ­ vs è¤‡æ•°äººã§ã®åˆ†å‰²
        multi_person_images = total_images - solo_only
        if solo_only > total_images * 0.3:
            print(f"  ğŸ¯ ã€Œã‚½ãƒ­ã€vsã€Œè¤‡æ•°äººã€ã§ã®åˆ†å‰²ãŒåŠ¹æœçš„")
            print(f"     - ã‚½ãƒ­ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹: {solo_only:,}ä»¶")
            print(f"     - è¤‡æ•°äººãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹: {multi_person_images:,}ä»¶")
        
        # æ€§åˆ¥ã«ã‚ˆã‚‹åˆ†å‰²
        if girls_only_images > total_images * 0.2 and boys_only_images > total_images * 0.1:
            print(f"  ğŸ¯ ã€Œå¥³æ€§ã®ã¿ã€vsã€Œç”·æ€§ã®ã¿ã€vsã€Œæ··åˆã€ã§ã®åˆ†å‰²ã‚‚æœ‰åŠ¹")
            print(f"     - å¥³æ€§ã®ã¿ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹: {girls_only_images:,}ä»¶")
            print(f"     - ç”·æ€§ã®ã¿ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹: {boys_only_images:,}ä»¶")
            print(f"     - æ··åˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹: {both_images + neither_images:,}ä»¶")
        
        # 4. æ¤œç´¢ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹äºˆæ¸¬
        print(f"\n4ï¸âƒ£  æ¤œç´¢ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹äºˆæ¸¬:")
        current_avg_search = total_images / 2  # å¹³å‡çš„ãªæ¤œç´¢å¯¾è±¡æ•°
        
        # ã‚½ãƒ­ vs è¤‡æ•°äººã§ã®åˆ†å‰²åŠ¹æœ
        if solo_only > total_images * 0.3:
            solo_db_avg = solo_only / 2
            multi_db_avg = multi_person_images / 2
            max_db_size = max(solo_db_avg, multi_db_avg)
            improvement = current_avg_search / max_db_size
            print(f"  - ç¾åœ¨ã®å¹³å‡æ¤œç´¢å¯¾è±¡: {current_avg_search:,.0f}ä»¶")
            print(f"  - ã‚½ãƒ­åˆ†å‰²å¾Œã®å¹³å‡æ¤œç´¢å¯¾è±¡: {solo_db_avg:,.0f}ä»¶")
            print(f"  - è¤‡æ•°äººåˆ†å‰²å¾Œã®å¹³å‡æ¤œç´¢å¯¾è±¡: {multi_db_avg:,.0f}ä»¶")
            print(f"  - äºˆæƒ³ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Š: {improvement:.1f}å€")
        
        # æœ€é©ãªåˆ†å‰²ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ææ¡ˆ
        print(f"\n5ï¸âƒ£  æœ€é©åˆ†å‰²ãƒ‘ã‚¿ãƒ¼ãƒ³:")
        print(f"  ğŸ“Š ç¾åœ¨ã®æ¤œç´¢æ™‚é–“ãŒ30ç§’ã®å ´åˆ:")
        if solo_only > total_images * 0.3:
            solo_time = 30 * (solo_db_avg / current_avg_search)
            multi_time = 30 * (multi_db_avg / current_avg_search)
            print(f"     - ã‚½ãƒ­DBæ¤œç´¢æ™‚é–“: {solo_time:.1f}ç§’")
            print(f"     - è¤‡æ•°äººDBæ¤œç´¢æ™‚é–“: {multi_time:.1f}ç§’")
    
    def save_results_to_file(self, results, filename="database_analysis.json"):
        """çµæœã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        # tag_combination_counterã®tupleã‚­ãƒ¼ã‚’æ–‡å­—åˆ—ã«å¤‰æ›
        results_copy = results.copy()
        results_copy['tag_combination_counter'] = {
            " + ".join(tags): count 
            for tags, count in results['tag_combination_counter'].items()
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(results_copy, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ’¾ è§£æçµæœã‚’ {filename} ã«ä¿å­˜ã—ã¾ã—ãŸ")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸ” ç”»åƒãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è§£æãƒ„ãƒ¼ãƒ«")
    print("GROUPSå¤‰æ•°ã®è¢«å†™ä½“æ•°ãƒ»çµ„ã¿åˆã‚ã›åˆ¥çµ±è¨ˆã‚’ä½œæˆã—ã¾ã™\n")
    
    try:
        analyzer = DatabaseAnalyzer()
        results = analyzer.analyze_tag_combinations()
        
        analyzer.print_analysis_results(results)
        analyzer.suggest_database_partitioning(results)
        analyzer.save_results_to_file(results)
        
        print(f"\nâœ… è§£æå®Œäº†!")
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()